{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dQ43lOKuJwwi",
    "outputId": "2fba0b0c-1d59-4ad2-c0cd-3ff6d0aaa44f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import streamlit as st\n",
    "# import pandas as pd\n",
    "# import joblib\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# import sklearn\n",
    "# import sklearn\n",
    "# import imblearn\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.pipeline import Pipeline as imbalanced_Pipeline\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import random\n",
    "# import numpy as np\n",
    "\n",
    "#  # for model persistence\n",
    "\n",
    "# # Load your pre-trained Gradient Boosting model\n",
    "# model = joblib.load('gb_classifier.pkl')\n",
    "# # preprocess_function = joblib.load(\"preprocess_data_function.pkl\")\n",
    "# # pipeline_function = joblib.load(\"pipeline_and_function.pkl\")\n",
    "\n",
    "# # Load the CSV file\n",
    "# df = pd.read_csv('Latest_epl_data.csv')\n",
    "\n",
    "# # Apply preprocessing to the loaded data\n",
    "#     # Convert 'Date' and 'Time_x' to datetime\n",
    "# df['Date'] = pd.to_datetime(df['Date'] + ' ' + df['Time_x'])\n",
    "# df['Time'] = pd.to_datetime(df['Time_x'], format='%H:%M').dt.time\n",
    "\n",
    "#     # Fill missing values in 'Attendance' with seasonal median\n",
    "# df['Season'] = df['Date'].dt.year\n",
    "# seasonal_median = df.groupby('Season')['Attendance'].transform('median')\n",
    "# df['Attendance'].fillna(seasonal_median, inplace=True)\n",
    "\n",
    "#     # Fill missing values in 'Dist' with overall median\n",
    "# median_dist = df['Dist'].median()\n",
    "# df['Dist'].fillna(median_dist, inplace=True)\n",
    "\n",
    "#     # Drop unnecessary columns\n",
    "# columns_to_drop = ['Time_x', 'Comp', 'xGA', 'xG', 'Captain', 'Referee', 'Match Report', 'Notes', 'Cmp.1', 'Cmp.2', 'Cmp.3', 'Att.1', 'Att.2',\n",
    "#                        'Att.3', 'Cmp%', 'Cmp%.1', 'Cmp%.2', 'Cmp%.3', 'Cmp.4', 'Cmp.5', 'Cmp.6', 'Cmp.7', 'Time_y']\n",
    "# df.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "# class MissingDict(dict):\n",
    "#     __missing__ = lambda self, key: key\n",
    "\n",
    "# map_values = {\"Brighton and Hove Albion \": \"Brighton\", \"Manchester United \": \"Manchester Utd\", \"Newcastle United \": \"Newcastle Utd\", \"Tottenham Hotspur \": \"Tottenham\", \"West Ham United \": \"West Ham\",\n",
    "#               \"Wolverhampton Wanderers \": \"Wolves\",'Newcastle United ': 'Newcastle Utd', 'West Ham United ': 'West Ham', 'Sheffield United ' : 'Sheffield Utd' }\n",
    "# mapping = MissingDict(**map_values)\n",
    "# df[\"Team\"] = df[\"Team\"].map(mapping)\n",
    "\n",
    "#     # Map 'W', 'D', 'L' to numeric values in the 'Result' column\n",
    "# result_mapping = {'W': 1, 'D': 0, 'L': 0}\n",
    "# df['Result'] = df['Result'].map(result_mapping)\n",
    "\n",
    "#     # Feature engineering\n",
    "# df['Cmp_Poss_Ratio'] = df['Cmp'] / df['Poss']\n",
    "# df['Cmp_PrgDist_Ratio'] = df['Cmp'] / df['PrgDist']\n",
    "\n",
    "#     # Drop specified features\n",
    "# features_to_drop = ['TotDist', 'Att', 'Poss', 'PrgDist']\n",
    "# df.drop(features_to_drop, axis=1, inplace=True)\n",
    "\n",
    "#     # Encode categorical features\n",
    "# df[\"Venue\"] = df[\"Venue\"].astype(\"category\").cat.codes\n",
    "# df[\"opp_encoded\"] = df[\"Opponent\"].astype(\"category\").cat.codes\n",
    "# df[\"team_encoded\"] = df[\"Team\"].astype(\"category\").cat.codes\n",
    "\n",
    "#     # Convert 'Time' to whole number\n",
    "# df['hour'] = df['Time'].astype(str).str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "#     # Map days of the week to code\n",
    "# df[\"day_encoded\"] = df[\"Date\"].dt.dayofweek\n",
    "\n",
    "#     # Convert 'Result' column from strings to integers\n",
    "# df[\"Target\"] = (df[\"Result\"] == \"W\").astype(\"int\")\n",
    "\n",
    "#     # Encode 'Formation' column\n",
    "# df[\"formation_encoded\"] = df[\"Formation\"].astype(\"category\").cat.codes\n",
    "\n",
    "#     # Create seasons\n",
    "# df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "#     # Define a function to determine the season\n",
    "# def get_season(date):\n",
    "#     if date.month >= 8:\n",
    "#         return date.year + 1\n",
    "#     else:\n",
    "#         return date.year\n",
    "\n",
    "#     # Apply the function to create a new 'Season' column\n",
    "# df['Season'] = df['Date'].apply(get_season)\n",
    "\n",
    "#     # Convert 'Round' column to integer codes using label encoding\n",
    "# df['Round_encoded'] = df['Round'].astype('category').cat.codes\n",
    "\n",
    "#     # Drop encoded categorical features\n",
    "# df.drop(columns=['Round', 'Day', 'Opponent', 'Formation', 'Team', 'Time', 'Date'], inplace=True)\n",
    "#     # Define the numerical columns (excluding 'Formation')\n",
    "# numerical_columns = ['GF', 'GA', 'Attendance', 'Sh', 'SoT', 'FK',\n",
    "#                      'Dist', 'PK', 'PKatt', 'Cmp', 'Cmp_Poss_Ratio', 'Cmp_PrgDist_Ratio', 'hour']\n",
    "\n",
    "#     # Define the target column\n",
    "# target_column = 'Result'\n",
    "\n",
    "# # set a fixed random seed for reporducibility\n",
    "# random.seed(42)\n",
    "# np.random.seed(42)\n",
    "\n",
    "# # Let's split our train, validation and test datasets\n",
    "\n",
    "# #Assuming you have a column named \"Season\" in your DataFrame\n",
    "# train_data = df[df['Season'] <= 2022]\n",
    "# test_data = df[df['Season'] > 2022]\n",
    "\n",
    "# #Further split the training data into training and validation sets\n",
    "# train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# #Separate features (X) and target variable (y) for training, validation, and test sets\n",
    "# X_train = train_data.drop(\"Result\", axis=1)  # Assuming \"Result\" is the target variable\n",
    "# y_train = train_data[\"Result\"]\n",
    "\n",
    "# X_val = val_data.drop(\"Result\", axis=1)\n",
    "# y_val = val_data[\"Result\"]\n",
    "\n",
    "# X_test = test_data.drop(\"Result\", axis=1)\n",
    "# y_test = test_data[\"Result\"]\n",
    "\n",
    "# # # Verify the shapes of the sets\n",
    "# # print(\"Train set shape:\", X_train.shape, y_train.shape)\n",
    "# # print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "# # print(\"Test set shape:\", X_test.shape, y_test.shape)\n",
    "\n",
    "#     # Create a column transformer for numeric variables\n",
    "# preprocessor_numeric = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', StandardScaler(), numerical_columns),\n",
    "#         ])\n",
    "\n",
    "\n",
    "#     # Create a PCA transformer for numeric variables.\n",
    "#     # Specify the number of principal components\n",
    "# pca = PCA(n_components=5)\n",
    "\n",
    "#     # PCA does not distinguish between real and synthetic samples.\n",
    "# imbalanced_pipeline = imbalanced_Pipeline([\n",
    "#     ('preprocessor_numeric', preprocessor_numeric),\n",
    "#      ('pca', pca),\n",
    "#       ('smote', SMOTE()),  # You might want to adjust SMOTE parameters\n",
    "# ])\n",
    "# # Applying the pipeline\n",
    "\n",
    "# X_train_resampled, y_train_resampled = imbalanced_pipeline.fit_resample(X_train, y_train)\n",
    "# X_val_resampled, y_val_resampled,  = imbalanced_pipeline.fit_resample(X_val, y_val)\n",
    "# X_test_resampled, y_test_resampled = imbalanced_pipeline.fit_resample(X_test, y_test)\n",
    "# # Sidebar for user input\n",
    "# st.sidebar.header('Match Details')\n",
    "# home_team = st.sidebar.selectbox('Select Home Team', df['team_encoded'].unique())\n",
    "# away_team = st.sidebar.selectbox('Select Away Team', df['team_encoded'].unique())\n",
    "\n",
    "# # Filter the data for the selected teams\n",
    "# selected_data = df[\n",
    "#     ((df['team_encoded'] == home_team) & (df['opp_encoded'] == away_team)) |\n",
    "#     ((df['opp_encoded'] == home_team) & (df['team_encoded'] == away_team))\n",
    "# ]\n",
    "\n",
    "# if not selected_data.empty:\n",
    "#     # Prepare the input features for prediction\n",
    "#     features = selected_data.drop(columns=['Result'])\n",
    "\n",
    "#     # Make the prediction\n",
    "#     prediction = model.predict(features)\n",
    "\n",
    "#     st.subheader('Match Prediction')\n",
    "#     st.write(f'Predicted Outcome: {prediction[0]}')\n",
    "# else:\n",
    "#     st.warning('No data available for the selected teams.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn\n",
    "import sklearn\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbalanced_Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    " # for model persistence\n",
    "\n",
    "# Load your pre-trained Gradient Boosting model\n",
    "model = joblib.load('gb_classifier.pkl')\n",
    "# preprocess_function = joblib.load(\"preprocess_data_function.pkl\")\n",
    "# pipeline_function = joblib.load(\"pipeline_and_function.pkl\")\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('Latest_epl_data.csv')\n",
    "\n",
    "# Apply preprocessing to the loaded data\n",
    "    # Convert 'Date' and 'Time_x' to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'] + ' ' + df['Time_x'])\n",
    "df['Time'] = pd.to_datetime(df['Time_x'], format='%H:%M').dt.time\n",
    "\n",
    "    # Fill missing values in 'Attendance' with seasonal median\n",
    "df['Season'] = df['Date'].dt.year\n",
    "seasonal_median = df.groupby('Season')['Attendance'].transform('median')\n",
    "df['Attendance'].fillna(seasonal_median, inplace=True)\n",
    "\n",
    "    # Fill missing values in 'Dist' with overall median\n",
    "median_dist = df['Dist'].median()\n",
    "df['Dist'].fillna(median_dist, inplace=True)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "columns_to_drop = ['Time_x', 'Comp', 'xGA', 'xG', 'Captain', 'Referee', 'Match Report', 'Notes', 'Cmp.1', 'Cmp.2', 'Cmp.3', 'Att.1', 'Att.2',\n",
    "                       'Att.3', 'Cmp%', 'Cmp%.1', 'Cmp%.2', 'Cmp%.3', 'Cmp.4', 'Cmp.5', 'Cmp.6', 'Cmp.7', 'Time_y']\n",
    "df.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "class MissingDict(dict):\n",
    "    __missing__ = lambda self, key: key\n",
    "\n",
    "map_values = {\"Brighton and Hove Albion \": \"Brighton\", \"Manchester United \": \"Manchester Utd\", \"Newcastle United \": \"Newcastle Utd\", \"Tottenham Hotspur \": \"Tottenham\", \"West Ham United \": \"West Ham\",\n",
    "              \"Wolverhampton Wanderers \": \"Wolves\",'Newcastle United ': 'Newcastle Utd', 'West Ham United ': 'West Ham', 'Sheffield United ' : 'Sheffield Utd' }\n",
    "mapping = MissingDict(**map_values)\n",
    "df[\"Team\"] = df[\"Team\"].map(mapping)\n",
    "\n",
    "    # Map 'W', 'D', 'L' to numeric values in the 'Result' column\n",
    "result_mapping = {'W': 1, 'D': 0, 'L': 0}\n",
    "df['Result'] = df['Result'].map(result_mapping)\n",
    "\n",
    "    # Feature engineering\n",
    "df['Cmp_Poss_Ratio'] = df['Cmp'] / df['Poss']\n",
    "df['Cmp_PrgDist_Ratio'] = df['Cmp'] / df['PrgDist']\n",
    "\n",
    "    # Drop specified features\n",
    "features_to_drop = ['TotDist', 'Att', 'Poss', 'PrgDist']\n",
    "df.drop(features_to_drop, axis=1, inplace=True)\n",
    "\n",
    "    # Encode categorical features\n",
    "df[\"Venue\"] = df[\"Venue\"].astype(\"category\").cat.codes\n",
    "df[\"opp_encoded\"] = df[\"Opponent\"].astype(\"category\").cat.codes\n",
    "df[\"team_encoded\"] = df[\"Team\"].astype(\"category\").cat.codes\n",
    "\n",
    "    # Convert 'Time' to whole number\n",
    "df['hour'] = df['Time'].astype(str).str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "    # Map days of the week to code\n",
    "df[\"day_encoded\"] = df[\"Date\"].dt.dayofweek\n",
    "\n",
    "    # Convert 'Result' column from strings to integers\n",
    "df[\"Target\"] = (df[\"Result\"] == \"W\").astype(\"int\")\n",
    "\n",
    "    # Encode 'Formation' column\n",
    "df[\"formation_encoded\"] = df[\"Formation\"].astype(\"category\").cat.codes\n",
    "\n",
    "    # Create seasons\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # Define a function to determine the season\n",
    "def get_season(date):\n",
    "    if date.month >= 8:\n",
    "        return date.year + 1\n",
    "    else:\n",
    "        return date.year\n",
    "\n",
    "    # Apply the function to create a new 'Season' column\n",
    "df['Season'] = df['Date'].apply(get_season)\n",
    "\n",
    "    # Convert 'Round' column to integer codes using label encoding\n",
    "df['Round_encoded'] = df['Round'].astype('category').cat.codes\n",
    "\n",
    "    # Drop encoded categorical features\n",
    "df.drop(columns=['Round', 'Day','Formation', 'Time', 'Date'], inplace=True)\n",
    "    # Define the numerical columns (excluding 'Formation')\n",
    "numerical_columns = ['GF', 'GA', 'Attendance', 'Sh', 'SoT', 'FK',\n",
    "                     'Dist', 'PK', 'PKatt', 'Cmp', 'Cmp_Poss_Ratio', 'Cmp_PrgDist_Ratio', 'hour']\n",
    "\n",
    "    # Define the target column\n",
    "target_column = 'Result'\n",
    "\n",
    "# Create a column transformer for numeric variables\n",
    "preprocessor_numeric = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "    ])\n",
    "\n",
    "# Create a PCA transformer for numeric variables.\n",
    "# Specify the number of principal components\n",
    "pca = PCA(n_components=5)\n",
    "\n",
    "# PCA does not distinguish between real and synthetic samples.\n",
    "imbalanced_pipeline = imbalanced_Pipeline([\n",
    "    ('preprocessor_numeric', preprocessor_numeric),\n",
    "    ('pca', pca),\n",
    "    ('smote', SMOTE()),  # You might want to adjust SMOTE parameters\n",
    "])\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Assuming you have a column named \"Season\" in your DataFrame\n",
    "train_data = df[df['Season'] <= 2022]\n",
    "test_data = df[df['Season'] > 2022]\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Separate features (X) and target variable (y) for training, validation, and test sets\n",
    "X_train = train_data.drop(\"Result\", axis=1)\n",
    "y_train = train_data[\"Result\"]\n",
    "\n",
    "X_val = val_data.drop(\"Result\", axis=1)\n",
    "y_val = val_data[\"Result\"]\n",
    "\n",
    "X_test = test_data.drop(\"Result\", axis=1)\n",
    "y_test = test_data[\"Result\"]\n",
    "\n",
    "# Applying the pipeline to training, validation, and test sets\n",
    "X_train_resampled, y_train_resampled = imbalanced_pipeline.fit_resample(X_train, y_train)\n",
    "X_val_resampled, y_val_resampled = imbalanced_pipeline.fit_resample(X_val, y_val)\n",
    "X_test_resampled, y_test_resampled = imbalanced_pipeline.fit_resample(X_test, y_test)\n",
    "\n",
    "# Set the wallpaper URL\n",
    "wallpaper_url = \"https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.fifplay.com%2Fpremier-league-2023-2024-predictions%2F&psig=AOvVaw2TD-wPijDxF3xqT6Pc8TKM&ust=1697573560984000&source=images&cd=vfe&opi=89978449&ved=0CA8QjRxqFwoTCLiGtsqw-4EDFQAAAAAdAAAAABAD.jpg\"  # Replace with the actual URL of your wallpaper\n",
    "\n",
    "# Add the wallpaper and styling to the background\n",
    "st.markdown(\n",
    "    f\"\"\"\n",
    "    <style>\n",
    "        body {{\n",
    "            background-image: url('{wallpaper_url}');\n",
    "            background-size: cover;\n",
    "        }}\n",
    "\n",
    "        .sidebar {{\n",
    "            background-color: #3498db;  /* Blue color for the sidebar */\n",
    "            padding: 10px;\n",
    "            border-radius: 10px;\n",
    "            margin: 10px;\n",
    "        }}\n",
    "\n",
    "        .predict-button {{\n",
    "            background-color: #ffffff;  /* White color for the predict button */\n",
    "            color: #3498db;  /* Blue color for the text on the button */\n",
    "            padding: 10px;\n",
    "            border-radius: 5px;\n",
    "            margin-top: 10px;\n",
    "            cursor: pointer;\n",
    "        }}\n",
    "\n",
    "        .predict-button:hover {{\n",
    "            background-color: #3498db;  /* Change color on hover */\n",
    "            color: #ffffff;\n",
    "        }}\n",
    "    </style>\n",
    "    \"\"\",\n",
    "    unsafe_allow_html=True\n",
    ")\n",
    "\n",
    "# Sidebar for user input with custom styling\n",
    "st.sidebar.header('Match Details')\n",
    "home_team = st.sidebar.selectbox('Select Home Team', df['Team'].unique())\n",
    "away_team = st.sidebar.selectbox('Select Away Team', df['Team'].unique())\n",
    "\n",
    "# Add a predict button with custom styling\n",
    "predict_button = st.sidebar.button('Predict Match', key='predict-button')\n",
    "\n",
    "if predict_button:\n",
    "    # Filter the data for the selected teams\n",
    "    selected_data = df[((df['Team'] == home_team) & (df['Opponent'] == away_team)) | ((df['Opponent'] == home_team) | (df['Team'] == away_team))]\n",
    "\n",
    "    if not selected_data.empty:\n",
    "        # Apply the same preprocessing to the selected data\n",
    "        selected_features, selected_labels = imbalanced_pipeline.fit_resample(selected_data.drop(columns=['Result']), \n",
    "                                                                              selected_data['Result'])\n",
    "\n",
    "        # Make the prediction\n",
    "        prediction = model.predict(selected_features)\n",
    "\n",
    "        # Determine the outcome based on the prediction (0 for loss or draw, 1 for win)\n",
    "        outcome = \"Win\" if prediction[0] == 1 else \"Loss or Draw\"\n",
    "        \n",
    "        # Display the result\n",
    "        st.subheader('Match Prediction')\n",
    "        st.write(f'{home_team} vs. {away_team}: {home_team} {outcome}')\n",
    "    else:\n",
    "        st.warning('No data available for the selected teams.')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
